#! /usr/bin/env python
# -*- coding: utf-8 -*-
# Authors: SDG DS unit
"""
This module generates reports based on data from a Qdrant database 
and a final prompt passed to a language model (LLM). It uses a 
retriever to query relevant data from the database and then generates 
a report based on the retrieved information. The module allows flexible 
configurations for report formats and LLM settings.

Functions:
    - inform_generator: Retrieves relevant data from Qdrant and generates a
     report using an LLM model.
"""

from qdrant_client import QdrantClient

from src.services.llm.call_llm import call_llm
from src.services.llm.prompts import create_final_prompt
from src.services.retrievers.selfq_retrievers import setup_retrievers


def inform_generator(
        qdrant_client: QdrantClient,
        formato: str,
        report_id: str,
        fecha: str,
        query: str,
        model: str = "llama-3.3-70b-specdec",
        temperature: float = 0.4,
        max_tokens: int = 15000,
) -> str:
    """
    Generates a report based on data from Qdrant and the final prompt
    passed to the LLM model.

    Args:
        qdrant_client (QdrantClient): The Qdrant client to interact with
        the database.
        formato (str): The report format ("summarized" or "extensive").
        report_id (str): The ID of the report.
        fecha (str): The date of the report.
        query (str): The query to be made to the model.
        model (str): The OpenAI model to use (optional, default is "llama-3.3-70b-specdec").
        temperature (float): The temperature for generation (optional, default is 0.4).
        max_tokens (int): The maximum number of tokens to generate (optional, default is 15000).

    Returns:
        str: The content generated by the LLM model.
    """
    # Assign each prompt to a variable
    doc_query = " and ".join([f"Report ID: {report_id}", f"Date: {str(fecha)}"])

    # Collection configuration
    if formato.lower() != "resumido":
        n_values = {"Text Pages": 20}
        collections = [{"name": "Text Pages", "n": 20}]
    else:
        n_values = {"Report Summaries": 1}
        collections = [{"name": "Report Summaries", "n": 1}]

    ensemble_retriever = setup_retrievers(
        qdrant_client=qdrant_client, 
        collections=collections, 
        n_values=n_values, 
        model="ms-marco-TinyBERT-L-2-v2"
    )

    # Invoke the retriever to get the documents
    documents = ensemble_retriever.invoke(input=doc_query)

    # Create the final prompt (directly returns a string)
    final_prompt = create_final_prompt(
        formato=formato, 
        query=query, 
        doc_query=doc_query, 
        documents=documents
    )

    # Generate the report content using the LLM
    report_content = call_llm(
        prompt=final_prompt,
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    return report_content
